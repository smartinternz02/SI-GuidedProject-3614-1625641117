{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a6f55b",
   "metadata": {},
   "source": [
    "# <center>Assignment 7</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1825faf7",
   "metadata": {},
   "source": [
    "## <center>Image Classification Using CNN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e8cd4",
   "metadata": {},
   "source": [
    "**Name               :** Atharva Ramgirkar  \n",
    "**Registration Number:** 19BCE0114  \n",
    "**Submission Date    :** 13 July, 2021  \n",
    "**Program            :** VIT-AI Industry Certifiation  \n",
    "**Email              :** atharva.ramgirkar2019@vitstudent.ac.in  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089a88e5",
   "metadata": {},
   "source": [
    "*Other Assignments can be found in the link:* **https://drive.google.com/drive/folders/1QGOLHyZykoj_CroTJu6-YkZWf32JZ-QH?usp=sharing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aadeb83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95d638a3",
   "metadata": {},
   "source": [
    "## <center>Table of Content</center>\n",
    "* [Importing Libraries](#1.-Importing-Libraries)  \n",
    "* [Setting Image Modification Parameters](#2.-Setting-Image-Modification-Parameters)\n",
    "* [Reading Images](#3.-Reading-Images)\n",
    "* [Model Building](#4.-Model-Building)\n",
    "    * [Model Initialization](#4.1-Model-Initialization)\n",
    "    * [Convolution Layer](#4.2-Convolution-Layer)\n",
    "    * [Pooling](#4.3-Pooling)\n",
    "    * [Flatten(Input Layer)](#4.4-Flatten(Input-Layer))\n",
    "    * [Hidden Layers](#4.5-Hidden-Layers)\n",
    "    * [Output Layer](#4.6-Output-Layer)\n",
    "* [Compiling the Model](#5.-Compiling-the-Model)\n",
    "* [Model Training and Testing](#6.-Model-Training-and-Testing)\n",
    "* [Single Predictions](#7.-Single-Predictions)\n",
    "* [Saving the Model](#8.-Saving-the-Model)\n",
    "* [Loading the Saved Model](#9.-Loading-the-Saved-Model)\n",
    "* [Making Predictions Using Loaded Model](#10.-Making-Predictions-Using-Loaded-Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3367c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa83854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dfd85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68a2354b",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea6af4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Convolution2D,MaxPooling2D,Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import ImageFile\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d314c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9c899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d86ea6b",
   "metadata": {},
   "source": [
    "### 2. Setting Image Modification Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fa3d77",
   "metadata": {},
   "source": [
    "[Back to Top](#Assignment-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf1a2502",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d33b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71bb576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e58eea6e",
   "metadata": {},
   "source": [
    "### 3. Reading Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f7dc5",
   "metadata": {},
   "source": [
    "[Back to Top](#Assignment-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f895cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5767 images belonging to 6 classes.\n",
      "Found 1145 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "X_train = train_datagen.flow_from_directory(\"seg_train/seg_train/\",\n",
    "                                            target_size=(64,64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode=\"categorical\")\n",
    "X_test = test_datagen.flow_from_directory(\"seg_test/seg_test/\",\n",
    "                                            target_size=(64,64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7bca25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buildings': 0,\n",
       " 'forest': 1,\n",
       " 'glacier': 2,\n",
       " 'mountain': 3,\n",
       " 'sea': 4,\n",
       " 'street': 5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d9464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21c5f517",
   "metadata": {},
   "source": [
    "### 4. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de0379f",
   "metadata": {},
   "source": [
    "[Back to Top](#Assignment-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db25408f",
   "metadata": {},
   "source": [
    "#### 4.1 Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fb9f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613445d",
   "metadata": {},
   "source": [
    "#### 4.2 Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6738fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(50,(5,5),input_shape=(64,64,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600b020",
   "metadata": {},
   "source": [
    "#### 4.3 Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a88b204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D((2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e8c51",
   "metadata": {},
   "source": [
    "#### 4.4 Flatten(Input Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e9a936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc0b39b",
   "metadata": {},
   "source": [
    "#### 4.5 Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0da39b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 100,\n",
    "                kernel_initializer=\"random_uniform\",\n",
    "                activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "929f16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 100,\n",
    "                kernel_initializer=\"random_uniform\",\n",
    "                activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2bfd8b",
   "metadata": {},
   "source": [
    "#### 4.6 Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd0bf7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 6,\n",
    "                kernel_initializer=\"random_uniform\",\n",
    "                activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2039b5",
   "metadata": {},
   "source": [
    "### 5. Compiling the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f2987",
   "metadata": {},
   "source": [
    "[Back to Top](#Assignment-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "492378e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac7ec9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3f9d157",
   "metadata": {},
   "source": [
    "### 6. Model Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eab617",
   "metadata": {},
   "source": [
    "[Back to Top](#Assignment-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9ac45ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "116/116 [==============================] - 20s 173ms/step - loss: 1.3004 - accuracy: 0.4949 - val_loss: 1.2314 - val_accuracy: 0.5400\n",
      "Epoch 2/25\n",
      "116/116 [==============================] - 19s 168ms/step - loss: 1.0863 - accuracy: 0.5872 - val_loss: 0.9958 - val_accuracy: 0.6137\n",
      "Epoch 3/25\n",
      "116/116 [==============================] - 18s 159ms/step - loss: 1.0050 - accuracy: 0.6119 - val_loss: 1.2430 - val_accuracy: 0.5450\n",
      "Epoch 4/25\n",
      "116/116 [==============================] - 18s 157ms/step - loss: 0.9875 - accuracy: 0.6176 - val_loss: 0.9409 - val_accuracy: 0.6500\n",
      "Epoch 5/25\n",
      "116/116 [==============================] - 18s 159ms/step - loss: 0.9032 - accuracy: 0.6629 - val_loss: 1.1671 - val_accuracy: 0.5850\n",
      "Epoch 6/25\n",
      "116/116 [==============================] - 19s 161ms/step - loss: 0.8924 - accuracy: 0.6566 - val_loss: 0.9853 - val_accuracy: 0.6575\n",
      "Epoch 7/25\n",
      "116/116 [==============================] - 18s 159ms/step - loss: 0.8342 - accuracy: 0.6778 - val_loss: 0.9717 - val_accuracy: 0.6550\n",
      "Epoch 8/25\n",
      "116/116 [==============================] - 19s 167ms/step - loss: 0.7964 - accuracy: 0.6959 - val_loss: 0.8586 - val_accuracy: 0.7013\n",
      "Epoch 9/25\n",
      "116/116 [==============================] - 18s 154ms/step - loss: 0.8041 - accuracy: 0.6951 - val_loss: 0.9023 - val_accuracy: 0.6812\n",
      "Epoch 10/25\n",
      "116/116 [==============================] - 18s 156ms/step - loss: 0.7497 - accuracy: 0.7155 - val_loss: 0.8768 - val_accuracy: 0.7000\n",
      "Epoch 11/25\n",
      "116/116 [==============================] - 19s 165ms/step - loss: 0.7330 - accuracy: 0.7338 - val_loss: 1.1328 - val_accuracy: 0.5987\n",
      "Epoch 12/25\n",
      "116/116 [==============================] - 19s 165ms/step - loss: 0.6707 - accuracy: 0.7497 - val_loss: 0.9689 - val_accuracy: 0.6600\n",
      "Epoch 13/25\n",
      "116/116 [==============================] - 19s 162ms/step - loss: 0.6642 - accuracy: 0.7581 - val_loss: 0.9857 - val_accuracy: 0.6600\n",
      "Epoch 14/25\n",
      "116/116 [==============================] - 19s 161ms/step - loss: 0.6245 - accuracy: 0.7716 - val_loss: 1.0678 - val_accuracy: 0.6637\n",
      "Epoch 15/25\n",
      "116/116 [==============================] - 19s 165ms/step - loss: 0.5944 - accuracy: 0.7762 - val_loss: 1.0719 - val_accuracy: 0.6762\n",
      "Epoch 16/25\n",
      "116/116 [==============================] - 19s 160ms/step - loss: 0.5609 - accuracy: 0.7958 - val_loss: 1.0022 - val_accuracy: 0.6900\n",
      "Epoch 17/25\n",
      "116/116 [==============================] - 19s 168ms/step - loss: 0.5597 - accuracy: 0.7809 - val_loss: 1.0306 - val_accuracy: 0.6875\n",
      "Epoch 18/25\n",
      "116/116 [==============================] - 20s 170ms/step - loss: 0.5453 - accuracy: 0.7955 - val_loss: 0.9202 - val_accuracy: 0.6875\n",
      "Epoch 19/25\n",
      "116/116 [==============================] - 19s 164ms/step - loss: 0.5153 - accuracy: 0.8160 - val_loss: 1.0507 - val_accuracy: 0.6875\n",
      "Epoch 20/25\n",
      "116/116 [==============================] - 19s 162ms/step - loss: 0.5207 - accuracy: 0.8023 - val_loss: 0.8912 - val_accuracy: 0.7225\n",
      "Epoch 21/25\n",
      "116/116 [==============================] - 19s 164ms/step - loss: 0.4656 - accuracy: 0.8196 - val_loss: 1.2429 - val_accuracy: 0.6550\n",
      "Epoch 22/25\n",
      "116/116 [==============================] - 19s 165ms/step - loss: 0.4615 - accuracy: 0.8283 - val_loss: 1.0876 - val_accuracy: 0.6725\n",
      "Epoch 23/25\n",
      "116/116 [==============================] - 20s 170ms/step - loss: 0.4373 - accuracy: 0.8421 - val_loss: 1.1787 - val_accuracy: 0.7088\n",
      "Epoch 24/25\n",
      "116/116 [==============================] - 19s 165ms/step - loss: 0.4153 - accuracy: 0.8421 - val_loss: 1.1640 - val_accuracy: 0.6712\n",
      "Epoch 25/25\n",
      "116/116 [==============================] - 19s 166ms/step - loss: 0.4394 - accuracy: 0.8346 - val_loss: 1.0602 - val_accuracy: 0.6787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2df2e138fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(X_train,\n",
    "                    steps_per_epoch=116,\n",
    "                    epochs=25,\n",
    "                    validation_data=X_test,\n",
    "                    validation_steps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f216e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69417ee6",
   "metadata": {},
   "source": [
    "### 7. Single Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecfcfb5",
   "metadata": {},
   "source": [
    "[Back to Top](#Assignment-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87d12bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"seg_test/seg_test/buildings/22421.jpg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d907c5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(np.expand_dims(img,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0082562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"seg_test/seg_test/forest/22854.jpg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "879b9d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(np.expand_dims(img,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66426fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"seg_test/seg_test/mountain/22537.jpg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "171e8a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(np.expand_dims(img,axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c5561",
   "metadata": {},
   "source": [
    "**All three single predictions are correct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c119c2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5bad299",
   "metadata": {},
   "source": [
    "### 8. Saving the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3bb7a7",
   "metadata": {},
   "source": [
    "[Back to Top](#Assignment-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dfd949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"nature.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c4f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c7eb8ee",
   "metadata": {},
   "source": [
    "### 9. Loading the Saved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e45ad5",
   "metadata": {},
   "source": [
    "[Back to Top](#Assignment-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "572d3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = load_model(\"nature.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a73f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c5b5810",
   "metadata": {},
   "source": [
    "### 10. Making Predictions Using Loaded Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5114ec",
   "metadata": {},
   "source": [
    "[Back to Top](#Assignment-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af80ccfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model_load.predict(np.expand_dims(img,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53478265",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"seg_test/seg_test/street/23253.jpg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ec75852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model_load.predict(np.expand_dims(img,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a634c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"seg_test/seg_test/sea/22736.jpg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4fe221a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model_load.predict(np.expand_dims(img,axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666a76e",
   "metadata": {},
   "source": [
    "**2 out of 3 predictions are correct from the Loaded Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e0284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1750ac4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "116/116 [==============================] - 22s 191ms/step - loss: 1.3372 - accuracy: 0.4689 - val_loss: 1.0544 - val_accuracy: 0.6025\n",
      "Epoch 2/25\n",
      "116/116 [==============================] - 19s 164ms/step - loss: 1.1257 - accuracy: 0.5622 - val_loss: 1.2840 - val_accuracy: 0.5763\n",
      "Epoch 3/25\n",
      "116/116 [==============================] - 20s 171ms/step - loss: 1.0254 - accuracy: 0.6073 - val_loss: 1.1511 - val_accuracy: 0.5962\n",
      "Epoch 4/25\n",
      "116/116 [==============================] - 20s 175ms/step - loss: 0.9607 - accuracy: 0.6368 - val_loss: 1.1444 - val_accuracy: 0.5825\n",
      "Epoch 5/25\n",
      "116/116 [==============================] - 20s 171ms/step - loss: 0.9249 - accuracy: 0.6507 - val_loss: 0.9663 - val_accuracy: 0.6550\n",
      "Epoch 6/25\n",
      "116/116 [==============================] - 19s 160ms/step - loss: 0.8524 - accuracy: 0.6753 - val_loss: 1.2021 - val_accuracy: 0.6037\n",
      "Epoch 7/25\n",
      "116/116 [==============================] - 19s 163ms/step - loss: 0.8172 - accuracy: 0.6989 - val_loss: 1.0007 - val_accuracy: 0.6438\n",
      "Epoch 8/25\n",
      "116/116 [==============================] - 20s 170ms/step - loss: 0.8164 - accuracy: 0.6995 - val_loss: 0.9305 - val_accuracy: 0.6725\n",
      "Epoch 9/25\n",
      "116/116 [==============================] - 19s 162ms/step - loss: 0.7841 - accuracy: 0.7006 - val_loss: 1.0116 - val_accuracy: 0.6475\n",
      "Epoch 10/25\n",
      "116/116 [==============================] - 18s 156ms/step - loss: 0.7353 - accuracy: 0.7258 - val_loss: 0.9060 - val_accuracy: 0.6875\n",
      "Epoch 11/25\n",
      "116/116 [==============================] - 18s 154ms/step - loss: 0.7091 - accuracy: 0.7290 - val_loss: 0.9732 - val_accuracy: 0.6600\n",
      "Epoch 12/25\n",
      "116/116 [==============================] - 18s 156ms/step - loss: 0.6890 - accuracy: 0.7390 - val_loss: 0.8936 - val_accuracy: 0.6875\n",
      "Epoch 13/25\n",
      "116/116 [==============================] - 18s 156ms/step - loss: 0.6348 - accuracy: 0.7694 - val_loss: 1.0259 - val_accuracy: 0.6600\n",
      "Epoch 14/25\n",
      "116/116 [==============================] - 18s 157ms/step - loss: 0.6251 - accuracy: 0.7643 - val_loss: 0.8946 - val_accuracy: 0.7025\n",
      "Epoch 15/25\n",
      "116/116 [==============================] - 20s 173ms/step - loss: 0.5882 - accuracy: 0.7804 - val_loss: 1.0174 - val_accuracy: 0.6775\n",
      "Epoch 16/25\n",
      "116/116 [==============================] - 19s 163ms/step - loss: 0.5772 - accuracy: 0.7863 - val_loss: 1.0883 - val_accuracy: 0.6325\n",
      "Epoch 17/25\n",
      "116/116 [==============================] - 20s 169ms/step - loss: 0.5520 - accuracy: 0.8009 - val_loss: 0.8582 - val_accuracy: 0.7325\n",
      "Epoch 18/25\n",
      "116/116 [==============================] - 20s 173ms/step - loss: 0.5591 - accuracy: 0.7931 - val_loss: 0.9575 - val_accuracy: 0.6800\n",
      "Epoch 19/25\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5143 - accuracy: 0.8068"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "                    steps_per_epoch=116,\n",
    "                    epochs=25,\n",
    "                    validation_data=X_test,\n",
    "                    validation_steps=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096d2af0",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
